{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics in Quantitative Finance, Summer 2023 \n",
    "\n",
    "## Lecture 5: Volatility and volatility-linked derivatives\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<font size=5, color=darkblue> Tai-Ho Wang (王 太和)</font>\n",
    "</center>\n",
    "<img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2016/04/MFE-Logo.jpg\" align = \"center\" width=450>\n",
    "\n",
    "$$\n",
    "\\newcommand{\\bea}{\\begin{eqnarray}}\n",
    "\\newcommand{\\eea}{\\end{eqnarray}}\n",
    "\\newcommand{\\supp}{\\mathrm{supp}}\n",
    "\\newcommand{\\F}{\\mathcal{F} }\n",
    "\\newcommand{\\cF}{\\mathcal{F} }\n",
    "\\newcommand{\\E}{\\mathbb{E} }\n",
    "\\newcommand{\\Eof}[1]{\\mathbb{E}\\left[ #1 \\right]}\n",
    "\\newcommand{\\Etof}[1]{\\mathbb{E}_t\\left[ #1 \\right]}\n",
    "\\def\\Cov{{ \\mbox{Cov} }}\n",
    "\\def\\ES{{ \\mbox{ES} }}\n",
    "\\def\\Var{{ \\mbox{Var} }}\n",
    "\\def\\VaR{{ \\mbox{VaR} }}\n",
    "\\def\\sd{{ \\mbox{sd} }}\n",
    "\\def\\corr{{ \\mbox{corr} }}\n",
    "\\newcommand{\\1}{\\mathbf{1} }\n",
    "\\newcommand{\\p}{\\partial}\n",
    "\\newcommand{\\PP}{\\mathbb{P} }\n",
    "\\newcommand{\\Pof}[1]{\\mathbb{P}\\left[ #1 \\right]}\n",
    "\\newcommand{\\QQ}{\\mathbb{Q} }\n",
    "\\newcommand{\\R}{\\mathbb{R} }\n",
    "\\newcommand{\\DD}{\\mathbb{D} }\n",
    "\\newcommand{\\HH}{\\mathbb{H} }\n",
    "\\newcommand{\\spn}{\\mathrm{span} }\n",
    "\\newcommand{\\cov}{\\mathrm{cov} }\n",
    "\\newcommand{\\HS}{\\mathcal{L}_{\\mathrm{HS}} }\n",
    "\\newcommand{\\Hess}{\\mathrm{Hess} }\n",
    "\\newcommand{\\trace}{\\mathrm{trace} }\n",
    "\\newcommand{\\LL}{\\mathcal{L} }\n",
    "\\newcommand{\\s}{\\mathcal{S} }\n",
    "\\newcommand{\\ee}{\\mathcal{E} }\n",
    "\\newcommand{\\ff}{\\mathcal{F} }\n",
    "\\newcommand{\\hh}{\\mathcal{H} }\n",
    "\\newcommand{\\bb}{\\mathcal{B} }\n",
    "\\newcommand{\\dd}{\\mathcal{D} }\n",
    "\\newcommand{\\g}{\\mathcal{G} }\n",
    "\\newcommand{\\half}{\\frac{1}{2} }\n",
    "\\newcommand{\\T}{\\mathcal{T} }\n",
    "\\newcommand{\\bit}{\\begin{itemize}}\n",
    "\\newcommand{\\eit}{\\end{itemize}}\n",
    "\\newcommand{\\beq}{\\begin{equation}}\n",
    "\\newcommand{\\eeq}{\\end{equation}}\n",
    "\\newcommand{\\tr}{\\mbox{tr}}\n",
    "\\newcommand{\\angl}[1]{\\langle #1 \\rangle}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "- Volatility and its various estimators\n",
    "    - Historical volatility\n",
    "    - Implied volatility\n",
    "    - Realized variance\n",
    "    - VIX \n",
    "- Implied volatility\n",
    "    - Estimating discount factor and dividend rates by put-call parity\n",
    "    - GPR fit of implied volatilities\n",
    "- Volatility indices published by CBOE\n",
    "- Volatility linked derivatives\n",
    "    - VIX option\n",
    "    \n",
    "- Appendix (Optional)\n",
    "    - Realized variance from high frequency data\n",
    "    - The Corsi HAR-RV forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is volatility?\n",
    "\n",
    "From the [Wikipage](https://en.wikipedia.org/wiki/Volatility_(finance)):\n",
    "\n",
    ">In finance, volatility (symbol $\\sigma$) is the degree of variation of a trading price series over time as measured by the standard deviation of logarithmic returns.\n",
    ">\n",
    ">- Historic volatility measures a time series of past market prices. \n",
    ">- Implied volatility looks forward in time, being derived from the market price of a market-traded derivative (in particular, an option). \n",
    ">- Realized variance estimates the integrated variance or quadratic variation by using high frequency data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is volatility important?\n",
    "\n",
    "From the same [Wikipage](https://en.wikipedia.org/wiki/Volatility_(finance)):\n",
    "\n",
    ">Investors care about volatility for at least the following reasons:\n",
    ">\n",
    ">- The wider the swings in an investment's price, the harder emotionally it is to not worry;\n",
    ">\n",
    ">- Price volatility of a trading instrument can define position sizing in a portfolio;\n",
    ">\n",
    ">- When certain cash flows from selling a security are needed at a specific future date, higher volatility means a greater chance of a shortfall;\n",
    ">\n",
    ">- Higher volatility of returns while saving for retirement results in a wider distribution of possible final portfolio values;\n",
    ">\n",
    ">- Higher volatility of return when retired gives withdrawals a larger permanent impact on the portfolio's value;\n",
    ">\n",
    ">- Price volatility presents opportunities to buy assets cheaply and sell when overpriced;\n",
    ">\n",
    ">- <font color=blue> Portfolio volatility has a negative impact on the compound annual growth rate (CAGR) of that portfolio </font>\n",
    ">\n",
    ">- Volatility affects pricing of options, being a parameter of the Black–Scholes model.\n",
    ">\n",
    "\n",
    "In today's markets, it is also possible to trade volatility directly, through the use of derivative securities such as options and variance swaps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatilities\n",
    "\n",
    "Volatiltiy of a financial asset in its most prelimanry form is defined as the (conditional) standard deviation of its log return. In practice, there exist various notions of \"volatility\" that are commonly used including  \n",
    "\n",
    "- Historical volatility\n",
    "- Realized and integrated variance/volatility\n",
    "- Implied volatility \n",
    "- Instantaneous volatility \n",
    "\n",
    "and methods of inferring these volatilities respectively from\n",
    "\n",
    "- Daily or high-frequency time series data of the underlying\n",
    "- Price series of variance swap\n",
    "- Prices of liquidly traded vanilla options\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical volatility\n",
    "\n",
    "Historical volatility uses, say daily, price series to calculate the sample conditional standard deviation of log returns in rolling time windows of a prespecified width.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Example of historical volatility\n",
    "\n",
    "Now let's calculate the volatility of S&P500 using 25-day rolling time windows. \n",
    "\n",
    "One can calculate the volatiltiy series of the input price series $S_t$, $1 \\leq t \\leq T$, by the following formula\n",
    "\n",
    "$$\n",
    "\\sigma_t = \\sqrt{\\frac N{n-2}\\sum_{i=1}^{n-1} (r_i - \\bar r)^2}, \\quad \\mbox{ for } n \\leq t \\leq T,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "&& r_i = \\ln S_{t + i} - \\ln S_{t + i - 1}, \\mbox{ for } 1 \\leq i \\leq n - 1\\\\\n",
    "&& \\bar r = \\frac1{n-1} \\sum_{i=1}^{n-1} r_i. \n",
    "\\end{eqnarray*}\n",
    "\n",
    "### Note\n",
    "- $n$ denotes the width (number of days) of rolling window\n",
    "- $N$ denotes the number of days in a year, thus $\\sqrt N$ is the annualizing factor\n",
    "- The first $n-1$ points in the output volatility series appear as NA, for an obvious reason.\n",
    "\n",
    "### Exponetially weighted moving average (EWMA)\n",
    "An alternative to calculate historical volatility is the *exponentially weighted moving average* method. \n",
    "\n",
    "$$\n",
    "\\sigma_t = \\sqrt{N(1 - \\lambda)\\sum_{i=1}^{\\infty} \\lambda^i (r_{t - i} - \\bar r)^2}, \\quad \\mbox{ for } n \\leq t \\leq T,\n",
    "$$\n",
    "\n",
    "for some $\\lambda \\in (0, 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's dirty our hands ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import exp, log, sqrt\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-07-29\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# download SPX from yahoo finance\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m spx \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^GSPC\u001b[39m\u001b[38;5;124m'\u001b[39m, start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yf' is not defined"
     ]
    }
   ],
   "source": [
    "start, end = '2019-01-01', '2022-07-29'\n",
    "# download SPX from yahoo finance\n",
    "spx = yf.download('^GSPC', start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief look at the data\n",
    "spx.info(), spx.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first and last few rows of the data\n",
    "spx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data, just in case\n",
    "#spx.to_csv('spx_07252022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved data\n",
    "#spx = pd.read_csv('spx_07252022.csv')\n",
    "#spx.index = spx['Date']\n",
    "#spx = spx.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "spx.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spx adjusted close\n",
    "plt.figure(figsize=(9, 6))\n",
    "spx['Adj Close'].plot()\n",
    "plt.ylabel('SPX', fontsize=12)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log return of spx \n",
    "r = log(spx['Adj Close']).diff()\n",
    "\n",
    "# historical volatility in this period\n",
    "vol = r.std()*sqrt(252)\n",
    "r, r.mean(), vol, type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot log return\n",
    "plt.figure(figsize=(9, 6))\n",
    "r.plot(lw=1)\n",
    "plt.ylabel('SPX log return', fontsize=12)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.iloc[0:10], r.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n: rwidth of rolling window\n",
    "# N: annualizing factor\n",
    "def volatility(data, n=10, N=252):\n",
    "    data = pd.Series(data)\n",
    "    vol = [np.nan for i in range(n)]\n",
    "    for i in range(len(data)-n):\n",
    "        vol += [data.iloc[i:(i+n)].std()*sqrt(N)]\n",
    "    return pd.DataFrame({'volatility': vol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility(r, n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_vol = volatility(r)\n",
    "spx_vol.index = r.index\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(spx_vol)\n",
    "plt.ylabel('Volatility', fontsize=12)\n",
    "plt.title('SPX historical volatility', fontsize=24)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leverage effect\n",
    "spx_scaled = (spx - spx.mean())/(spx.max() - spx.min())\n",
    "plt.figure(figsize=(9, 6))\n",
    "spx_scaled['Adj Close'].plot(color='k', lw=1, label='scaled spx')\n",
    "plt.ylim([-0.6, 1])\n",
    "plt.plot(spx_vol, 'b-.', lw=1, label='volatility')\n",
    "plt.grid()\n",
    "plt.title('Leverage effect', fontsize=24)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility estimation using OHLC\n",
    "\n",
    "- Parkison\n",
    "- Garman-Klass\n",
    "- Rogers-Satchell\n",
    "- Yang-Zhang\n",
    "\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "&& \\sigma_P^2 = \\frac1{4\\ln2} \\frac1n\\sum_{i=1}^n (\\ln H_i - \\ln L_i)^2 \\\\\n",
    "&& \\sigma_{GK}^2 = \\frac1n \\left\\{\\sum_{i=1}^n \\frac12(\\ln H_i - \\ln L_i)^2 + (2\\ln2 - 1)(\\ln C_i - \\ln O_i)^2 \\right\\} \\\\\n",
    "&& \\sigma_{RS}^2 = \\frac1n \\sum_{i=1}^n u_i(u_i - c_i) + d_i(d_i - c_i) \\\\\n",
    "&& \\sigma_{YZ}^2 = \\sigma_O^2 + w\\sigma_C^2 + (1 - w)\\sigma_P^2, \\quad w = \\frac{0.34}{1.34 + \\frac{n+1}{n-1}}.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "- $u_i = \\ln H_i - \\ln O_i$: daily high weighted by open, \n",
    "- $d_i = \\ln L_i - \\ln O_i$: daily low weighted by open\n",
    "- $o_i = \\ln O_i - \\ln C_{i-1}$\n",
    "- $c_i = \\ln C_i - \\ln O_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the calculation of these volatilties into a python `class`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Volatilities:\n",
    "    def __init__(self, OHLC, n=10, N=252):\n",
    "        self.n = n\n",
    "        self.N = N\n",
    "        self.OHLC = pd.DataFrame(OHLC)\n",
    "        self.o = self.OHLC.Open\n",
    "        self.h = self.OHLC.High\n",
    "        self.l = self.OHLC.Low\n",
    "        self.c = self.OHLC.Close\n",
    "        self.r = log(self.OHLC['Adj Close']).diff()\n",
    "        self.vols_c = [np.nan for i in range(self.n)] \n",
    "        self.vols_p = [np.nan for i in range(self.n)]\n",
    "        self.vols_gk = [np.nan for i in range(self.n)] \n",
    "        self.vols_rs = [np.nan for i in range(self.n)] \n",
    "        \n",
    "        for i in range(len(self.r) - self.n):\n",
    "            self.vols_c += [self.r.iloc[i:(i+self.n)].std()*sqrt(self.N)]\n",
    "            self.vols_p += [self.cal_vol_p(self.h.iloc[i:(i+self.n)], self.l.iloc[i:(i+self.n)])*sqrt(self.N)]\n",
    "            self.vols_gk += [self.cal_vol_gk(self.o.iloc[i:(i+self.n)], self.h.iloc[i:(i+self.n)], self.l.iloc[i:(i+self.n)], self.c.iloc[i:(i+self.n)])*sqrt(self.N)]\n",
    "            self.vols_rs += [self.cal_vol_rs(self.o.iloc[i:(i+self.n)], self.h.iloc[i:(i+self.n)], self.l.iloc[i:(i+self.n)], self.c.iloc[i:(i+self.n)])*sqrt(self.N)]\n",
    "        self.vols = pd.DataFrame({'close': self.vols_c, 'parkinson': self.vols_p, 'garman-klass': self.vols_gk, 'rogers-satchell': self.vols_rs})\n",
    "        self.vols.index = self.OHLC.index\n",
    "        \n",
    "    def cal_vol_p(self, H, L):\n",
    "        return np.sqrt(((log(H) - log(L))**2).mean()/log(2)/4)\n",
    "    \n",
    "    def cal_vol_gk(self, O, H, L, C):\n",
    "        term1 = ((log(O) - log(L))**2).mean()/2\n",
    "        term2 = (2*log(2) - 1)*((log(C) - log(O))**2).mean()\n",
    "        return np.sqrt(term1 + term2)\n",
    "    \n",
    "    def cal_vol_rs(self, O, H, L, C):\n",
    "        u, d, c = log(H) - log(O), log(L) - log(O), log(C) - log(O)\n",
    "        return np.sqrt((u*(u-c)).mean() + (d*(d-c)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spx_vols = Volatilities(spx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "spx_vols.vols['close'].plot(ls='--', label='Close', lw=0.8)\n",
    "spx_vols.vols['parkinson'].plot(lw=0.8, label='Parkinson')\n",
    "spx_vols.vols['garman-klass'].plot(lw=0.8, label='Garman-Klass')\n",
    "spx_vols.vols['rogers-satchell'].plot(lw=0.8, label='Rogers-Satchell')\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implied volatility\n",
    "\n",
    "\"A wrong number to a wrong formula for a correct answer.\"\n",
    "\n",
    "- In the Black-Scholes model there is a one-to-one relation between the price of the option and the volatility parameter $\\sigma$. The option prices are often quoted by stating this specific volatility, called the *implied volatility*.\n",
    "\n",
    "- In Black-Scholes world, the volatility is assumed constant. But in reality, options of different strike require different volatilities to match their market prices. This is called the *volatility smile*.\n",
    "\n",
    "- Most of the work was inspired in modeling the implied volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why implied volatility rather than the price itself?\n",
    "\n",
    "- Price of a call option is decreasing in strike and increasing in time to expiry\n",
    "- Price of a far out-of-money option is small whereas price of a far in-the-money option carries mostly the intrinsic value\n",
    "- Statistically speaking, implied volatility is a more standard quantity to infer\n",
    "- Traders trade options in terms of implied volatilities rather than their prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A practical tip for fetching risk free and dividend rates\n",
    "\n",
    "Q: How to obtain the interest rate $r$ and dividend rate $d$ for the calculation of implied volatility?\n",
    "\n",
    "A: Put-call parity.\n",
    "\n",
    "Recall the Put-Call Parity for European options\n",
    "\n",
    "$$\n",
    "C - P = Se^{-dT}  - K e^{-rT} = e^{-rT} (F - K),\n",
    "$$\n",
    "\n",
    "where $F$ denotes the forward price of the underlying. \n",
    "Hence, if we regress $C - P$ against $K$, the (negative) slope gives us the discount factor and the intercept gives the ex-dividend underlying.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Implied volatilities of options on SPX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "from numpy import exp, log, sqrt\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download spx options data from yahoo finance\n",
    "spx = yf.Ticker('^SPX')\n",
    "spx_expiries = spx.options\n",
    "print(spx_expiries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an expiry \n",
    "idx = 17\n",
    "today = dt.strftime(dt.now(), '%Y-%m-%d')\n",
    "day_count = (dt.strptime(spx_expiries[idx], '%Y-%m-%d') - dt.now()).days\n",
    "print(f'option expiry = {spx_expiries[idx]}, today = {today}')\n",
    "print(f'There are {day_count} days to expiry')\n",
    "spx_calls, spx_puts = spx.option_chain(spx_expiries[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_calls.shape, spx_puts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_calls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_calls.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_puts.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up data\n",
    "# remove NA's\n",
    "spx_calls = spx_calls.drop(['currency', 'contractSize'], axis=1).dropna()\n",
    "spx_puts = spx_puts.drop(['currency', 'contractSize'], axis=1).dropna()\n",
    "spx_calls.shape, spx_puts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_calls[spx_calls['lastTradeDate'] > '2022-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data point where either bid = 0 or ask = 0\n",
    "# remove data that that are not traded recently\n",
    "spx_calls = spx_calls[(spx_calls['bid'] > 0) & (spx_calls['ask'] > 0)]\n",
    "#spx_calls[spx_calls['lastTradeDate'] > '2022-07']\n",
    "spx_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_puts = spx_puts[(spx_puts['bid'] > 0) & (spx_puts['ask'] > 0)]\n",
    "#spx_puts = spx_puts[spx_puts['lastTradeDate'] > '2022-02']\n",
    "spx_puts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv\n",
    "#spx_calls.to_csv('spxcall_07252022.csv', index=False)\n",
    "#spx_puts.to_csv('spxput_07252022.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read saved spx option data\n",
    "spx_calls = pd.read_csv('spxcall_07252022.csv')\n",
    "spx_puts = pd.read_csv('spxput_07252022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create `python` class `OptionAnalytics`\n",
    "\n",
    "Wrap everything up in a python class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptionAnalytics:\n",
    "    def __init__(self, option_chain, expiry, today):\n",
    "        self.expiry = expiry\n",
    "        self.today = today\n",
    "        if not type(today) == datetime.datetime:\n",
    "            self.today = dt.strptime(today, '%Y-%m-%d')\n",
    "        self.calls, self.puts = option_chain\n",
    "        self.ks_c = self.calls['strike']\n",
    "        self.cs = (self.calls['bid'] + self.calls['ask'])/2 \n",
    "        self.ks_p = self.puts['strike'] \n",
    "        self.ps = (self.puts['bid'] + self.puts['ask'])/2         \n",
    "        # strikes that are traded for both calls and puts\n",
    "        self.ks = np.array([])\n",
    "        for k in self.ks_c:\n",
    "            if k in np.array(self.ks_p):\n",
    "                self.ks = np.concatenate([self.ks, [k]])\n",
    "\n",
    "        self.mids_call = np.array([])\n",
    "        for k in self.ks:\n",
    "            self.calls[self.calls['strike'] == k]['bid']\n",
    "            bid = self.calls[self.calls['strike'] == k]['bid']\n",
    "            ask = self.calls[self.calls['strike'] == k]['ask']\n",
    "            self.mids_call = np.concatenate([self.mids_call, np.array((bid + ask)/2)])\n",
    "\n",
    "        self.mids_put = np.array([])\n",
    "        for k in self.ks:\n",
    "            bid = self.puts[self.puts['strike'] == k]['bid']\n",
    "            ask = self.puts[self.puts['strike'] == k]['ask']\n",
    "            self.mids_put = np.concatenate([self.mids_put, np.array((bid + ask)/2)])\n",
    "            \n",
    "        tmp = self.imp_vols()\n",
    "        self.ivs, self.s_adj = tmp['imp_vols'], tmp['s_adj']\n",
    "        \n",
    "    # put-call parity plot \n",
    "    def plot_parity(self):\n",
    "        plt.figure(figsize=(9, 5))\n",
    "        plt.plot(self.ks, self.mids_call - self.mids_put, 'r.--')\n",
    "        plt.ylabel(r'$C - P$', fontsize=12)\n",
    "        plt.xlabel(r'$K$', fontsize=12)\n",
    "        plt.title(f'Expiry: {self.expiry}', fontsize=15);\n",
    "        return None\n",
    "            \n",
    "    def plot_arb(self):\n",
    "        # monotonicity and convexity for option premia vs strikes\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "        axes[0].plot(self.ks_c, self.cs, 'bo--')\n",
    "        axes[0].set_ylabel('Option mid price', fontsize=12)\n",
    "        axes[0].set_xlabel('Strike', fontsize=12)\n",
    "        axes[1].plot(self.ks_p, self.ps, 'ro--')\n",
    "        axes[1].set_xlabel('Strike', fontsize=12);\n",
    "        return None\n",
    "        \n",
    "    # plot implied vol\n",
    "    def plot_imp_vols1(self):\n",
    "        ivs_c = self.calls['impliedVolatility']\n",
    "        ivs_p = self.puts['impliedVolatility']\n",
    "        # plot \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.ks_p, ivs_p, 'ro--', label='implied vol from puts')\n",
    "        plt.plot(self.ks_c, ivs_c, 'bo--', label='implied vol from calls')\n",
    "        plt.title(f'Expiration date: {self.expiry}', fontsize=15)\n",
    "        plt.xlabel('Strikes', fontsize=12)\n",
    "        plt.ylabel('Impliied Volatilities', fontsize=12)\n",
    "        plt.legend();\n",
    "        return None\n",
    "        \n",
    "    # Black-Scholes formula for call\n",
    "    def bs_call(self, s, K, t, sigma, r=0):\n",
    "        d1 = (log(s/K) + r*t)/(sigma*sqrt(t)) + sigma*sqrt(t)/2\n",
    "        d2 = d1 - sigma*sqrt(t)\n",
    "        return s*norm.cdf(d1) - K*exp(-r*t)*norm.cdf(d2)\n",
    "    \n",
    "    # function calculating implied vol by the bisection method\n",
    "    def bs_impvol_call(self, s0, K, T, C, r=0):\n",
    "        K = np.array([K])\n",
    "        n = len(K)\n",
    "        sigmaL, sigmaH = 1e-10*np.ones(n), 10*np.ones(n)\n",
    "        CL, CH = self.bs_call(s0, K, T, sigmaL, r), self.bs_call(s0, K, T, sigmaH, r)\n",
    "        while np.mean(sigmaH - sigmaL) > 1e-10:\n",
    "            sigma = (sigmaL + sigmaH)/2\n",
    "            CM = self.bs_call(s0, K, T, sigma, r)\n",
    "            CL = CL + (CM < C)*(CM - CL)\n",
    "            sigmaL = sigmaL + (CM < C)*(sigma - sigmaL)\n",
    "            CH = CH + (CM >= C)*(CM - CH)\n",
    "            sigmaH = sigmaH + (CM >= C)*(sigma - sigmaH)    \n",
    "        return sigma[0]\n",
    "    \n",
    "    # calculate implied vols\n",
    "    def imp_vols(self):\n",
    "        # regress call - put over strike K \n",
    "        # apply put-call parity \n",
    "        df = {'CP': self.mids_call - self.mids_put, 'Strike': self.ks}\n",
    "        result = sm.ols(formula='CP ~ Strike', data=df).fit()\n",
    "        s_adj, pv = result.params[0], -result.params[1]\n",
    "        ks_pv = self.ks*pv\n",
    "        days_to_expiry = (dt.strptime(self.expiry, '%Y-%m-%d') - self.today).days\n",
    "        imp_vols = self.bs_impvol_call(s_adj, ks_pv, days_to_expiry/365, self.mids_call, r=0)        \n",
    "        return {'imp_vols': imp_vols, 'pv': pv, 's_adj': s_adj}\n",
    "    \n",
    "    # plot implied vol\n",
    "    def plot_imp_vols2(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        y = self.ivs[self.ivs>0.001]\n",
    "        x = self.ks[self.ivs>0.001]\n",
    "        plt.plot(log(x/self.s_adj), y, 'b.--')\n",
    "        plt.plot(log(x/self.s_adj), y, 'r.')\n",
    "        plt.xlabel('logmoneyness', fontsize=12)\n",
    "        plt.ylabel('implied volatilities', fontsize=12)\n",
    "        plt.title('Implied volatilities vs Logmoneyness', fontsize=15);\n",
    "        return None\n",
    "    \n",
    "    def __call__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expiry = '2022-08-26'\n",
    "today = '2022-07-25'\n",
    "# today = dt.now()\n",
    "spx_opt = OptionAnalytics([spx_calls, spx_puts], expiry, today)\n",
    "#spx_opt = OptionAnalytics([spx_calls, spx_puts], spx_expiries[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt.plot_arb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt.plot_parity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt.imp_vols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt.plot_imp_vols2(), spx_opt.plot_imp_vols1();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A shorter time to expiry option on SPX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an expiry \n",
    "idx = 5\n",
    "today = dt.strftime(dt.now(), '%Y-%m-%d')\n",
    "day_count = (dt.strptime(spx_expiries[idx], '%Y-%m-%d') - dt.now()).days\n",
    "print(f'option expiry = {spx_expiries[idx]}, today = {today}')\n",
    "print(f'There are {day_count} days to expiry')\n",
    "spx_calls1, spx_puts1 = spx.option_chain(spx_expiries[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "spx_calls1 = spx_calls1.dropna()\n",
    "spx_calls1 = spx_calls1[(spx_calls1['bid'] > 0) & (spx_calls1['ask'] > 0)]\n",
    "spx_puts1 = spx_puts1.dropna()\n",
    "spx_puts1 = spx_puts1[(spx_puts1['bid'] > 0) & (spx_puts1['ask'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.now()\n",
    "spx_opt1 = OptionAnalytics([spx_calls1, spx_puts1], spx_expiries[idx], today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt1.plot_arb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt1.plot_parity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt1.s_adj, spx_opt1.imp_vols()['pv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_opt1.plot_imp_vols2(), spx_opt1.plot_imp_vols1();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPR fit for SPX implied volatility curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The posterior mean function from GPR\n",
    "# inputs: \n",
    "# m: prior mean function \n",
    "# k: prior kernel\n",
    "# y: observations\n",
    "# x: indices\n",
    "# \n",
    "# output: the posterior mean function\n",
    "\n",
    "def pos_mean(m, k, y, x, sigma=0.001):\n",
    "    n = len(x)\n",
    "    \n",
    "    # calculate the covariance matrices\n",
    "    tmp, _ = np.meshgrid(x, x)\n",
    "    Sigma_YY = k(tmp, _)\n",
    "    Sigma_YY = Sigma_YY + sigma**2*np.identity(n)\n",
    "    \n",
    "    # determine Sigma_YY_inv(Y - EY) by solving the linear system Sigma_YY x = Y - EY\n",
    "    Sigma_YY_inv_Y_EY = np.linalg.solve(Sigma_YY, y - m(x))\n",
    "    \n",
    "    # return the posterior mean function\n",
    "    return lambda xx: m(xx) + sum(k(xx, x)*Sigma_YY_inv_Y_EY)\n",
    "\n",
    "\n",
    "# The posterior kernel from GPR\n",
    "# inputs: \n",
    "# k: prior kernel\n",
    "# x: indices\n",
    "# \n",
    "# output: the posterior kernel\n",
    "\n",
    "def pos_kernel(k, x, sigma=0.1):\n",
    "    n = len(x)\n",
    "    \n",
    "    # calculate the covariance matrices\n",
    "    tmp, _ = np.meshgrid(x, x)\n",
    "    Sigma_YY = k(tmp, _)\n",
    "    Sigma_YY = Sigma_YY + sigma**2*np.identity(n)\n",
    "    \n",
    "    # return the posterior kernel\n",
    "    def _(xx, xp):\n",
    "        # determine Sigma_YY_inv Sigma_Yxp by solving the linear system Sigma_YY x = Sigma_Yxp\n",
    "        Sigma_YY_inv_Yxp = np.linalg.solve(Sigma_YY, k(xp, x))\n",
    "        Sigma_xY = k(xx, x)\n",
    "        return k(xx, xp) - sum(Sigma_xY*Sigma_YY_inv_Yxp)\n",
    "        \n",
    "    return _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_vols = spx_opt.ivs\n",
    "logmnyns = np.log(spx_opt.ks/spx_opt.s_adj)\n",
    "\n",
    "# set hyperparameters by guessing\n",
    "A, l, sigma = 0.1, 0.1, 0.01\n",
    "\n",
    "# prior mean function\n",
    "# set prior mean as sample mean of implied vols\n",
    "iv_mean = imp_vols.mean()\n",
    "mpr = lambda x: iv_mean\n",
    "\n",
    "# prior kernel\n",
    "k = lambda x, y: A*np.exp(-np.abs(x-y)**2/2/l**2)\n",
    "\n",
    "# indices and observations\n",
    "x_is = logmnyns\n",
    "n = len(x_is)\n",
    "y_is = imp_vols\n",
    "\n",
    "# posterior mean function for implied vol\n",
    "mpo_iv = pos_mean(mpr, k, y_is, x_is, sigma=sigma)\n",
    "mpo_iv = np.vectorize(mpo_iv)\n",
    "mpo_iv(x_is)\n",
    "\n",
    "\n",
    "# fitted values\n",
    "iv_hat = mpo_iv(x_is)\n",
    "pd.DataFrame(y_is, iv_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(x_is, y_is, 'bo', label='Market data')\n",
    "plt.xlabel('logmoneyness')\n",
    "plt.ylabel('implied vol')\n",
    "x = np.linspace(x_is.min(), x_is.max(), 200)\n",
    "plt.plot(x, mpo_iv(x), 'r--', label='GPR fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis on absolute errors \n",
    "abs_errs = np.abs(iv_hat - y_is)\n",
    "plt.plot(x_is, abs_errs, 'bo')\n",
    "plt.xlabel('logmoneyness', fontsize=12) \n",
    "plt.ylabel('errors', fontsize=12)\n",
    "pd.DataFrame(abs_errs).describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune hyperparameters by MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the hyperparameters by MLE\n",
    "\n",
    "# objective function\n",
    "def obj(x, y):\n",
    "    def _(params):\n",
    "        A, l, sigma = params\n",
    "        k = lambda u, v: A*np.exp(-np.abs(u-v)**2/2/l**2)\n",
    "        n = len(x)\n",
    "        # calculate the covariance matrices\n",
    "        tmp, _ = np.meshgrid(x, x)\n",
    "        Sigma_YY = k(tmp, _)\n",
    "        Sigma_YY = Sigma_YY + sigma**2*np.identity(n)\n",
    "        Sigma_YY_inv_y = np.linalg.solve(Sigma_YY, y)        \n",
    "        return np.log(np.linalg.det(Sigma_YY)) + sum(y*Sigma_YY_inv_y) #this is in fact negative log likelihood\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# minimize objective function\n",
    "print(obj(x_is, y_is)([0.1, 0.1, 0.1]))\n",
    "pars = [0.1, 0.1, 0.1]\n",
    "res = minimize(obj(x_is, y_is), pars, method='nelder-mead', \n",
    "               options={'xatol': 1e-8, 'disp': True}) \n",
    "hyparams = res.x\n",
    "hyparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters estimated from MLE\n",
    "A, l, sigma = hyparams\n",
    "\n",
    "# prior mean function\n",
    "# set prior mean as sample mean of implied vols\n",
    "iv_mean = imp_vols.mean()\n",
    "mpr = lambda x: iv_mean\n",
    "\n",
    "# prior kernel\n",
    "k = lambda x, y: A*np.exp(-np.abs(x-y)**2/2/l**2)\n",
    "\n",
    "# indices and observations\n",
    "x_is = logmnyns\n",
    "n = len(x_is)\n",
    "y_is = imp_vols\n",
    "\n",
    "# posterior mean function for implied vol\n",
    "mpo_iv = pos_mean(mpr, k, y_is, x_is, sigma=sigma)\n",
    "mpo_iv = np.vectorize(mpo_iv)\n",
    "#mpo_iv(x_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(x_is, y_is, 'bo', label='Market data')\n",
    "plt.xlabel('logmoneyness')\n",
    "plt.ylabel('implied vol')\n",
    "x = np.linspace(x_is.min(), x_is.max(), 200)\n",
    "plt.plot(x, mpo_iv(x), 'r--', label='GPR fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis on absolute errors \n",
    "abs_errs = np.abs(iv_hat - y_is)\n",
    "plt.plot(x_is, abs_errs, 'bo')\n",
    "plt.xlabel('logmoneyness', fontsize=12) \n",
    "plt.ylabel('errors', fontsize=12)\n",
    "pd.DataFrame(abs_errs).describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is VIX?\n",
    "\n",
    "Quote from [this page](https://www.investopedia.com/terms/v/vix.asp) in Investopedia:\n",
    "\n",
    ">Created by the Chicago Board Options Exchange (CBOE), the Volatility Index, or VIX, is a real-time market index that represents the market's expectation of 30-day forward-looking volatility. Derived from the price inputs of the S&P 500 index options, it provides a measure of market risk and investors' sentiments. It is also known by other names like \"Fear Gauge\" or \"Fear Index.\" Investors, research analysts and portfolio managers look to VIX values as a way to measure market risk, fear and stress before they take investment decisions. \n",
    "\n",
    ">Introduced in 1993, the Volatility Index (VIX) was initially a weighted measure of the implied volatility (IV) of eight S&P 100 at-the-money put and call options. Ten years later, in 2004, it expanded to use options based on a broader index, the S&P 500. This expansion allows for a more accurate view of investors' expectations on future market volatility. VIX values higher than 30 are usually associated with a significant amount of volatility as a result of investor fear or uncertainty. Values below 15 ordinarily correspond to less stressful, or even complacent, times in the markets.\n",
    "\n",
    "\n",
    "- Originally, the VIX computation was designed to mimic the implied volatility of an at-the-money 1 month option on the OEX index. It did this by averaging volatilities from 8 options (puts and calls from the closest to ATM strikes in the nearest and next to nearest months).\n",
    "\n",
    "- The CBOE changed the VIX computation: “CBOE is changing VIX to provide a more precise and robust measure of expected market volatility and to create a viable underlying index for tradable volatility products.”\n",
    "\n",
    "- CBOE listed futures on the VIX in 2004."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility indices published by CBOE\n",
    "\n",
    "In addition to VIX, other volatility indices published by [CBOE](http://www.cboe.com/products/vix-index-volatility/volatility-on-stock-indexes/cboe-s-p-500-9-day-vol-index-vix9d) include\n",
    "\n",
    "- VIX9D\n",
    "- VIX3M\n",
    "- VIX6M\n",
    "- VOX\n",
    "- VXD: Dow Jones index volatility\n",
    "- RVX\n",
    "- VXN\n",
    "- VVIX: VIX of VIX.\n",
    "\n",
    "### Note\n",
    "More volatility indices published by CBOE can be found in [this link](http://www.cboe.com/Volatility)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Formula of finanical engineering\"\n",
    "\n",
    "Notice that all payoffs we saw before can be expressed as a combination of payoffs from calls and puts, even the underlying itself since it can be regarded as a call struck at zero. A natural question to ask is, to what extent, can a given payoff function be represented as a combination of calls and puts?\n",
    "\n",
    "The answer is surprisingly \"all the payoffs\"! The following formula shows how. \n",
    "\n",
    "Let $\\varphi$ be a payoff function, we have\n",
    "\n",
    "$$\n",
    "\\varphi(s) = \\varphi(f) + \\varphi'(f)(s - f) + \\int_f^\\infty (s - k)^+ \\varphi''(k) dk + \\int_0^f (k - s)^+ \\varphi''(k)dk.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\delta$ denote the Dirac delta function and $\\theta$ the Heaviside function. Note that heuristically $\\theta' = \\delta$, i.e., the Dirac delta can be regarded as the derivative of the Heaviside function. \n",
    "\n",
    "The payoff $\\varphi(s)$ at time $T$ can be written as \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varphi(s) &=& \\int_0^\\infty \\varphi(k) \\delta(s - k)\\,dk \\\\\n",
    "&=& \\int_0^f \\varphi(k) \\delta(s - k) dk + \\int_f^\\infty \\varphi(k) \\delta(s - k) dk \\\\\n",
    "&=& \\varphi(f) - \\int_0^f \\varphi'(k) \\theta(k - s) dk + \\int_f^\\infty \\varphi'(k)\\theta(s - k) dk \\\\\n",
    "&=& \\varphi(f) + \\varphi'(f) (s - f) + \\int_0^f \\varphi''(k) (k - s)^+ dk + \\int_f^\\infty \\varphi''(k) (s - k)^+ dk.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Thus, \n",
    "\n",
    "$$\n",
    "\\varphi(S_T) = \\varphi(f) + \\varphi'(f) (S_T - f) + \\int_0^f \\varphi''(k) (k - S_T)^+ dk + \\int_f^\\infty \\varphi''(k) (S_T - k)^+ dk.\n",
    "$$\n",
    "\n",
    "With $f = \\Eof{S_T}$ and taking expectation on both sides, we end up \n",
    "\\begin{eqnarray*}\n",
    "\\Eof{\\varphi(S_T)} &=&\n",
    "% \\int_0^f\\,\\varphi''(K)\\,(K-S_T)^+\\,dK + \\int_F^\\infty\\,g''(k)\\,(S_T - k)^+\\,dK \\\\\n",
    "% &&+ g(F) - g'(F)\\,\\left[ (F-S_T)^+ - (S_T-F)^+ \\right] \\\\\n",
    "% &=&\n",
    " \\varphi(f) + \\int_0^f \\, \\varphi''(k) \\, P(k) \\,dk + \\int_f^\\infty\\, \\varphi''(k)\\, C(k) \\,dk.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "- The price of any European style contingent claim can be expressed in terms of strips of out-of-money European options. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - log contract\n",
    "\n",
    "Consider the log contract $\\varphi(s) = \\log s$. Since $\\varphi'(s) = \\frac1s$ and $\\varphi''(s) = -\\frac1{s^2}$, we obtain\n",
    "\n",
    "$$\n",
    "\\log s = \\log f + \\frac{s - f}{f} - \\int_0^f \\frac{(k - s)^+}{k^2} dk - \\int_f^\\infty \\frac{(s - k)^+}{k^2} dk. \n",
    "$$\n",
    "\n",
    "Thus, \n",
    "\n",
    "$$\n",
    "\\Eof{\\log S_T} = \\log f - \\int_0^f \\, \\frac{P(k)}{k^2} \\,dk - \\int_f^\\infty\\, \\frac{C(k)}{k^2} \\,dk.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, assume $S_t$ satisfies the SDE under risk neutral probability with zero interest and dividend rates\n",
    "\n",
    "$$\n",
    "\\frac{dS_t}{S_t} = \\sigma_t dW_t,\n",
    "$$\n",
    "\n",
    "by applying Ito's formula to $\\log S_t$, we obtain\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\log S_T = \\log S_0 + \\int_0^T \\sigma_t dW_t - \\frac12 \\int_0^T \\sigma_t^2 dt.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "It follows by taking expectation on both sides that \n",
    "\n",
    "$$\n",
    "\\Eof{\\log S_T} = \\log S_0 - \\frac12 \\Eof{\\int_0^T \\sigma_t^2 dt}\n",
    "$$\n",
    "\n",
    "Compare the two identities we obtain\n",
    "\n",
    "$$\n",
    "\\frac1T \\Eof{\\int_0^T \\sigma_t^2 dt} = \\frac2T \\int_0^f \\, \\frac{P(k)}{k^2} \\,dk + \\frac2T \\int_f^\\infty\\, \\frac{C(k)}{k^2} \\,dk.\n",
    "$$\n",
    "\n",
    "\n",
    "### Note\n",
    "- Modulo the diffusion process assumption on the underlying, the last relationship is model-free.  \n",
    "- VIX is calculated based on this formula with $T$ equal to a month.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is VIX calculated?\n",
    "\n",
    "VIX definition in the CBOE white paper:\n",
    "\n",
    "$$VIX^2=\\frac{2}{T}\\,\\sum_i\\,\\frac{\\Delta K_i}{K_i^2}\\,\n",
    "Q_i(K_i)\\,-\\,\\frac{1}{T}\\,\\left[\\frac{F}{K_0}-1\\right]^2\n",
    "$$\n",
    "\n",
    "where $Q_i$ is the price of the out-of-the-money option with strike\n",
    "$K_i$ and $K_0$ is the highest strike below the forward price $F$. $T$ is one month.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download VIX data from `yfinance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2007-01-01'\n",
    "end = '2022-07-29'\n",
    "vix = yf.download('^VIX', start=start, end=end)\n",
    "vix = vix.drop('Volume', axis=1)\n",
    "vix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "vix['Adj Close'].plot(label='VIX')\n",
    "#plt.plot(spx_vol*100, 'r-.', label='Historical Volatility')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot log(vix)\n",
    "plt.figure(figsize=(9, 6))\n",
    "log(vix)['Adj Close'].plot(label='log ViX')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility derivatives\n",
    "\n",
    "- variance swap\n",
    "- volatility swap\n",
    "- VIX futures\n",
    "- VIX options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance swap\n",
    "\n",
    "Quote from the [Wikipage](https://en.wikipedia.org/wiki/Variance_swap):\n",
    "\n",
    "> A variance swap is an over-the-counter financial derivative that allows one to speculate on or hedge risks associated with the magnitude of movement, i.e. volatility, of some underlying product, like an <font color=blue> exchange rate </font>, <font color=blue>interest rate</font>, or stock index.\n",
    "\n",
    "> One leg of the swap will pay an amount based upon the realized variance of the price changes of the underlying product. Conventionally, these price changes will be daily log returns, based upon the most commonly used closing price. The other leg of the swap will pay a fixed amount, which is the strike, quoted at the deal's inception. Thus the net payoff to the counterparties will be the difference between these two and will be settled in cash at the expiration of the deal, though some cash payments will likely be made along the way by one or the other counterparty to maintain agreed upon margin. \n",
    "\n",
    "In summary, a variance swap is a forward contract on realized (annualized) variance whose payoff function ideally is given by  \n",
    "\n",
    "$$\n",
    "N \\times \\left(\\frac1T \\int_0^T \\sigma_t^2 dt - K \\right)\n",
    "$$\n",
    "\n",
    "where $K$ is the strike and $N$ denotes the notional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility swap\n",
    "\n",
    "Quote from the [Wikipage](https://en.wikipedia.org/wiki/Volatility_swap):\n",
    "\n",
    ">In finance, a volatility swap is a forward contract on the future realised volatility of a given underlying asset. Volatility swaps allow investors to trade the volatility of an asset directly, much as they would trade a price index.\n",
    "\n",
    ">The underlying is usually a foreign exchange (FX) rate (very liquid market) but could be as well a single name equity or index. However, the variance swap is preferred in the equity market because it can be replicated with a linear combination of options and a dynamic position in futures.\n",
    "\n",
    ">Unlike a stock option, whose volatility exposure is contaminated by its stock price dependence, these swaps provide pure exposure to volatility alone. This is truly the case only for forward starting volatility swaps. However, once the swap has its asset fixings its mark-to-market value also depends on the current asset price. One can use these instruments to speculate on future volatility levels, to trade the spread between realized and implied volatility, or to hedge the volatility exposure of other positions or businesses. \n",
    "\n",
    "\n",
    "In summary, a volatility swap is a forward contract on realized (annualized) volatility whose payoff function ideally is given by  \n",
    "\n",
    "$$\n",
    "N \\times \\left(\\sqrt{\\frac1T \\int_0^T \\sigma_t^2 dt} - K \\right)\n",
    "$$\n",
    "\n",
    "where $K$ is the strike and $N$ denotes the notional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating volatility swap fair strike from MGF\n",
    "\n",
    "By applying the following formula\n",
    "\n",
    "$$\n",
    "\\sqrt x = \\frac1{2\\sqrt\\pi}\\int_0^\\infty s^{-\\frac32}\\left(1 - e^{-xs}\\right) ds,\n",
    "$$\n",
    "\n",
    "we obtain  \n",
    "\n",
    "$$\n",
    "\\Eof{\\sqrt{\\frac1T \\int_0^T \\sigma_t^2 dt}} = \\frac1{2\\sqrt\\pi}\\int_0^\\infty s^{-\\frac32}\\left(1 - \\Eof{e^{-xs}}\\right) ds\n",
    "$$\n",
    "\n",
    "where apparently,\n",
    "\n",
    "$$\n",
    "x = \\frac1T \\int_0^T \\sigma_t^2 dt\n",
    "$$\n",
    "\n",
    "and $\\Eof{e^{-xs}}$ the moment generating function for realized variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIX futures\n",
    "\n",
    "According to the [VIX page](https://cfe.cboe.com/cfe-products/vx-cboe-volatility-index-vix-futures) on CBOE,\n",
    "\n",
    ">Introduced in 2004 on Cboe Futures Exchange (CFE), VIX futures provide market participants with the ability to trade a liquid volatility product based on the VIX Index methodology. VIX futures reflect the market's estimate of the value of the VIX Index on various expiration dates in the future. VIX futures provide market participants with a variety of opportunities to implement their view using volatility trading strategies, including risk management, alpha generation and portfolio diversification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIX option\n",
    "\n",
    "Quote from [this page](https://www.investopedia.com/terms/v/vixoption.asp) in Invstopeida \n",
    "\n",
    ">A VIX option is a non-equity index option that uses the CBOE Volatility Index as its underlying asset. Call and put VIX options are both available. The call options hedge portfolios against a sudden market decline, and put options hedge against a rapid reversal of short positions on the S&P 500 index. These options thus allow traders and investors to speculate on future moves in volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the VIX option chain from Yahoo Finance\n",
    "Visit this [Yahoo Finance link for VIX option chain](https://finance.yahoo.com/quote/%5EVIX/options/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix = yf.Ticker('^VIX')\n",
    "vix_expiries = vix.options\n",
    "print(vix_expiries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an expiry \n",
    "idx = 4\n",
    "today = dt.strftime(dt.now(), '%Y-%m-%d')\n",
    "day_count = (dt.strptime(vix_expiries[idx], '%Y-%m-%d') - dt.now()).days\n",
    "print(f'option expiry = {vix_expiries[idx]}, today = {today}')\n",
    "print(f'There are {day_count} days to expiry')\n",
    "vix_calls, vix_puts = vix.option_chain(vix_expiries[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "vix_calls = vix_calls.drop(['currency', 'contractSize'], axis = 1).dropna()\n",
    "vix_calls = vix_calls[(vix_calls['bid'] > 0) & (vix_calls['ask'] > 0)]\n",
    "vix_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_puts = vix_puts.drop(['currency', 'contractSize'], axis = 1).dropna()\n",
    "vix_puts = vix_puts[(vix_puts['bid'] > 0) & (vix_puts['ask'] > 0)]\n",
    "vix_puts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "#vix_calls.to_csv('vixcall_07252022.csv', index=False)\n",
    "#vix_puts.to_csv('vixput_07252022.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in saved data\n",
    "vix_calls = pd.read_csv('vixcall_07252022.csv')\n",
    "vix_puts = pd.read_csv('vixput_07252022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expiry, today = '2022-08-24', '2022-07-25'\n",
    "vix_opt = OptionAnalytics([vix_calls, vix_puts], expiry, today)\n",
    "#vix_opt = OptionAnalytics([vix_calls, vix_puts], vix_expiries[idx], dt.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_opt.plot_arb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_opt.plot_parity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_opt.plot_imp_vols2(), vix_opt.plot_imp_vols1();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPR fit for VIX option implied volatility curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_vols = vix_opt.ivs[1:]\n",
    "#imp_vols = vix_opt.ivs\n",
    "logmnyns = np.log(vix_opt.ks[1:]/vix_opt.s_adj)\n",
    "\n",
    "# set hyperparameters by guessing\n",
    "sigma, A, l = 0.05, 0.1, 0.1\n",
    "\n",
    "# prior mean function\n",
    "# set prior mean as sample mean of implied vols\n",
    "iv_mean = imp_vols.mean()\n",
    "mpr = lambda x: iv_mean\n",
    "\n",
    "# prior kernel\n",
    "k = lambda x, y: A*np.exp(-np.abs(x-y)**2/2/l**2)\n",
    "\n",
    "# indices and observations\n",
    "x_is = logmnyns\n",
    "n = len(x_is)\n",
    "y_is = imp_vols\n",
    "\n",
    "# posterior mean function for implied vol\n",
    "mpo_iv = pos_mean(mpr, k, y_is, x_is, sigma=sigma)\n",
    "mpo_iv = np.vectorize(mpo_iv)\n",
    "mpo_iv(x_is)\n",
    "\n",
    "\n",
    "# fitted values\n",
    "iv_hat = mpo_iv(x_is)\n",
    "pd.DataFrame(y_is, iv_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(x_is, y_is, 'bo', label='Market data')\n",
    "plt.xlabel('logmoneyness')\n",
    "plt.ylabel('implied vol')\n",
    "x = np.linspace(x_is.min(), x_is.max(), 200)\n",
    "plt.plot(x, mpo_iv(x), 'r--', label='GPR fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis on absolute errors \n",
    "abs_errs = np.abs(iv_hat - y_is)\n",
    "plt.plot(x_is, abs_errs, 'bo')\n",
    "plt.xlabel('logmoneyness', fontsize=12) \n",
    "plt.ylabel('errors', fontsize=12)\n",
    "pd.DataFrame(abs_errs).describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility estimation using high frequency data\n",
    "\n",
    "- Market microstructure noise may contaminate the data in high frequency, resulting in inconsistency of estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realized variance\n",
    "\n",
    "The following estimator is called the *Realized Variance (RV)* estimator\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n \\, \\left(Y_{t_i} - Y_{t_{i-1}} \\right)^2\n",
    "= \\sum_{i=1}^n \\, \\left( \\Delta Y_{t_i} \\right)^2, \n",
    "$$ \n",
    "\n",
    "where $Y_t = \\log S_t$ and $S_t$ is the price series of the asset under consideration.\n",
    "\n",
    "\n",
    "### Technical notes\n",
    "\n",
    "- Realized variance and realized covariance <br>\n",
    "    Given a partition $\\Pi = \\{0 = t_1 < \\cdots < t_n=T\\}$ of the interval $[0, T]$, the realized variance $[X]_T^\\Pi$ of the process $X_t$ sampled at $\\Pi$ is defined by\n",
    "$$\n",
    "[X]_T^\\Pi = \\sum_{i=1}^n |X_{t_i} - X_{t_{i-1}}|^2.\n",
    "$$\n",
    "    Similiarly, the realized covariance between $X_t$ and $Y_t$ sampled at $\\Pi$ is given by \n",
    "$$\n",
    "[X, Y]_T^\\Pi = \\sum_{i=1}^n (X_{t_i} - X_{t_{i-1}})(Y_{t_i} - Y_{t_{i-1}})\n",
    "$$\n",
    "\n",
    "- Quadratic variation (integrated variance) and covariation <br>\n",
    "    The quadratic variation of $X$ is defined by the limit\n",
    "    $$\n",
    "    \\angl{X}_t = \\lim_{\\|\\Pi_n\\| \\to 0} [X]_T^{\\Pi_n} \n",
    "    $$\n",
    "    provided the limit exists. $\\Pi_n$ denotes a sequence of partitions of the interval $[0, T]$ such that $\\|\\Pi_n\\| \\to 0$ as $n \\to \\infty$, where $\\|\\Pi_n\\|$ denotes the mesh of the partition $\\Pi_n$. \n",
    "\n",
    "    Likewise, the covariation between and $X$ and $Y$ is defined by the limit\n",
    "    $$\n",
    "    \\angl{X, Y}_t = \\lim_{\\|\\Pi_n\\| \\to 0} [X, Y]_T^{\\Pi_n}.\n",
    "    $$\n",
    "\n",
    "\n",
    "\n",
    "### Assumption\n",
    "The log price $X_t$ follows the Ito process\n",
    "\n",
    "$$\n",
    "dX_t = \\mu_t dt + \\sigma_t dW_t,\n",
    "$$\n",
    "\n",
    "where $W_t$ is a Brownian motion. Under the assumption,\n",
    "$\\angl{X}_t = \\int_0^t \\sigma_\\tau^2 d\\tau$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated variance or quadratic variation\n",
    "\n",
    "Given a set of tick data, how can we measure the, say daily, variance? <br>\n",
    "A possibility is to estimate the *integrated variance*, also known as the *quadratic variation* in the theory of semimartingale. We shall use both terms interchangeably hereafter. \n",
    "\n",
    "Recall that the *quadratic variation* $\\angl{X}_t$ of the continuous stochastic process $X_t$ is defined by \n",
    "\n",
    "$$\n",
    "\\angl{X}_T:= \\lim_{\\|\\Pi_n\\| \\to 0} \\sum_{{t_i} \\in \\Pi_n} |\\Delta X_{t_i}|^2\n",
    "$$\n",
    "\n",
    "provided the limit exist (in probability). \n",
    "\n",
    "Thus, the goal is to estimate the quadratic variation of the efficient log price from the transacted log price, i.e., tick data. However, the subtlety is that efficient price is not directly observable and is contaminated by market microstructure noises.\n",
    "\n",
    "#### Note\n",
    "- If the process $X$ has jumps, the quadratic variation $\\angl{X}$ becomes\n",
    "\n",
    "    $$\n",
    "    \\angl{X}_t = \\angl{X^c}_t + \\sum_{0 < s \\leq t} |\\Delta X_s|^2,\n",
    "    $$\n",
    "\n",
    "    where $X^c$ denotes the continuous part of $X$ and $\\Delta X_s := X_s - X_{s^-}$ is the jump size at time $s$. In this case, the integrated variance usually refers to $\\angl{X^c}$, i.e., the quadratic variation of the continuous part. \n",
    "\n",
    "- We shall always assume $X$ is a continuous process, thus no jumps, in the sequel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microstructure noise\n",
    "\n",
    "In the limit of very high sampling frequency, RV picks up mainly the market\n",
    "microstructure noise. To see this, suppose that the observed price $Y_t$\n",
    "is given by\n",
    "\n",
    "$$Y_t =X_t +\\epsilon_t,$$\n",
    "\n",
    "where $X_t$ is the value of the\n",
    "underlying (log-)price process of interest and $\\epsilon_t$ is a random\n",
    "market microstructure-related noise term, assumed independent of $X_t$. Suppose we sample the price\n",
    "series $n+1$ times (so that there are $n$ price changes) at $\\Pi=\\{0=t_0 < \\cdots < t_n = T\\}$ in the time interval $[0, T]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, conditioned on $\\cF_T^X$, the conditional expectation of the realized variance of transacted (log) price satisties\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\Eof{[Y]_T^\\Pi |\\cF_T^X} &:=& \\sum_{i=1}^n \\Eof{(\\Delta Y_{t_i})^2|\\cF_T^X} \\\\\n",
    "&=& \\sum_{i=1}^n \\, (\\Delta X_{t_i})^2 + 2 \\sum_{i=1}^n \\Delta X_{t_i} \\Eof{\\Delta \\epsilon_{t_i}|\\cF_T^X} + \\sum_{i=1}^n \\Eof{(\\Delta \\epsilon_{t_i})^2|\\cF_T^X} \\\\\n",
    "&=& [X]_T + 2 n \\, \\mbox{var}[\\epsilon] \\\\\n",
    "&\\approx& \\angl{X}_T + 2 n \\, \\mbox{var}[\\epsilon].\n",
    "\\end{eqnarray*}\n",
    "\n",
    "#### Note\n",
    "The difference between $[X]_T$ and $\\angl{X}_T$ is referred to as the *discretization error*, which is usually controled by the integrated quarticity $\\int_0^T \\sigma_t^4 dt$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asymptotic result\n",
    "\n",
    "A more detailed, but more technical, asymptotic analysis shown in [Zhang, Mykland and Aït-Sahalia]<sup id=\"cite_ref-ZMA\" class=\"reference\"><a href=\"#cite_note-ZMA\">[9]</a></sup> yields that as $n \\to \\infty$\n",
    "\n",
    "$$\n",
    "[Y]^{\\Pi}_T \\mathop{\\approx}^{\\mathcal L} \\angl{X}_T + 2 \\, n \\, \\mbox{var}[\\epsilon] + \\sqrt{ 4 n \\Eof{\\epsilon^4} + \\frac{2T}{n} \\int_0^T \\sigma_t^4 dt} \\; Z,\n",
    "$$\n",
    "\n",
    "where $Z \\sim N(0,1)$.\n",
    "\n",
    "#### Note\n",
    "- The naive RV estimator $[Y]_T^\\Pi$ is biased by the variance of market microstructure noise $\\epsilon$. The biasedness increases as the sampling frequency $n$ increases.  \n",
    "- We see that as $n\\to\\infty$, the naive RV estimator $[Y]_T^\\Pi$ picks up mainly the microstructure noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### The conventional solution\n",
    "\n",
    "-   The conventional solution is to sample at most every five minutes or\n",
    "    so.\n",
    "\n",
    "    -  For high frequency data, sampling only every 5 minutes usually corresponds to throwing out more than 99% of the points!\n",
    "        \n",
    "-   To quote [Zhang, Mykland and Aït-Sahalia]<sup id=\"cite_ref-ZMA\" class=\"reference\"><a href=\"#cite_note-ZMA\">[9]</a></sup>, “It is difficult to accept\n",
    "    that throwing away data, especially in such quantities, can be an\n",
    "    optimal solution.”\n",
    "\n",
    "-   From a more practical perspective, if we believe that volatility is\n",
    "    time-varying, it makes sense to try and measure it from recent data\n",
    "    over the last few minutes rather than from a whole day of trading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling\n",
    "\n",
    "Let $\\Pi^{(k)} = \\{0 \\leq t_0^{(k)} < \\cdots < t_{n_k}^{(k)}\\leq T\\}$, for $1 \\leq k \\leq K$, be a collection of nonoverlapping subsampling times in $\\Pi$. That is, \n",
    "\n",
    "$$\n",
    "\\bigcup_{k=1}^K \\Pi^{(k)} = \\Pi \\quad \\mbox{ and } \\quad \\Pi^{(k)} \\cap \\Pi^{(\\ell)} = \\emptyset \\; \\mbox{for } k \\neq \\ell.\n",
    "$$\n",
    "\n",
    "A typical example that we shall be using in the following is by sampling every $K$ ticks from the $k$th tick on. That is, \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "&& \\Pi^{(1)} = \\{t_1 < t_{1+K} < t_{1 + 2K} < \\cdots < t_{1 + n_1 K} \\leq T \\}, \\\\\n",
    "&& \\Pi^{(2)} = \\{t_2 < t_{2+K} < t_{2 + 2K}< \\cdots < t_{2 + n_2 K} \\leq T \\}, \\\\\n",
    "&& \\qquad \\vdots \\\\\n",
    "&& \\Pi^{(K)} = \\{t_0 < t_K < t_{2K}  < \\cdots < t_{n_K K} \\leq  T \\}.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We denote by $[Y]_T^{\\Pi^{(k)}}$ the RV estimate of $Y$ using the subsamples that are sampled from the sampling times in $\\Pi^{(k)}$, for $1 \\leq k \\leq K$.\n",
    "\n",
    "By the same token, we have the following asymptotics for each subsample $k \\in \\{1, \\cdots, K\\}$\n",
    "\n",
    "$$\n",
    "[Y]^{\\Pi^{(k)}}_T \\mathop{\\approx}^{\\mathcal L} \\angl{X}_T + 2 \\, n_k \\, \\mbox{var}[\\epsilon] + \\sqrt{ 4 n_k \\Eof{\\epsilon^4} + \\frac{2T}{n_k} \\int_0^T \\sigma_t^4 dt} \\; Z_k\n",
    "$$\n",
    "\n",
    "where $Z_k \\sim N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting RV estimator\n",
    "\n",
    "We can boost the RV estimator by averaging over the \"weak learners\" $[Y]_T^{\\Pi^{(k)}}$\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "[Y]_T^{avg} &=& \\frac{1}{K} \\, \\sum_{k=1}^K \\, [Y]_T^{\\Pi^{(k)}} \\\\\n",
    "&\\approx& \\angl{X}_T + 2 \\, \\bar n_K \\, \\mbox{var}[\\epsilon] + \\sqrt{ 4 \\frac{\\bar n_K}K \\Eof{\\epsilon^4} + \\frac{4T}{3 \\bar n_K} \\int_0^T \\sigma_t^4 dt} \\; Z\n",
    "\\end{eqnarray*}\n",
    "    \n",
    "where $\\bar n_K := \\frac1K \\sum_k n_k $ is the average number of ticks in each subsample, roughly equal to $\\frac nK$.\n",
    "\n",
    "\n",
    "#### Note\n",
    "- Boosting reduces biasedness and variance by a factor of $K$, but is unable to completely remove the biasedness.\n",
    "- The optimal average subsample size $\\bar n^*$ is given by\n",
    "$$\n",
    "\\bar n^* = \\sqrt[3]{\\frac T{6\\mbox{var}^2[\\epsilon]} \\int_0^T \\sigma_t^4 dt}.\n",
    "$$\n",
    "    Thus, the whole sample set is splitted into roughly $K^* \\approx \\frac n{\\bar n^*}$ sets of subsamples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ZMA estimator\n",
    "\n",
    "Recall that \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "&& [Y]^\\Pi_T \\approx \\angl{X}_T + n \\, \\mbox{var}[\\epsilon], \\\\\n",
    "&& [Y]^{avg}_T \\approx \\angl{X}_T + \\bar n_K \\mbox{var}[\\epsilon].\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We can eliminate bias by forming\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac1{\\bar n_K}[Y]_T^{avg} - \\frac1n \\, [Y]_T^\\Pi \\approx \\left( \\frac1{\\bar n_K} - \\frac1n \\right) \\angl{X}_T.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Thus we obtain the [Zhang, Mykland and Aït-Sahalia]<sup id=\"cite_ref-ZMA\" class=\"reference\"><a href=\"#cite_note-ZMA\">[9]</a></sup> (ZMA) bias-corrected\n",
    "estimator of $\\angl{X}_T$:\n",
    "\n",
    "$$\n",
    "[Y]_T^{ZMA} := \\frac{1}{n - \\bar n_K} \\, \\left\\{n \\, [Y]_T^{avg} - \\bar n_K \\, [Y]^\\Pi_T \\right\\}.\n",
    "$$\n",
    "\n",
    "Moreover, we have the asymptotic behavior for $[Y]_T^{ZMA}$ as\n",
    "\n",
    "$$\n",
    "[Y]_T^{ZMA} \\approx \\angl{X}_T + \\frac1{\\sqrt[6]n}\\sqrt{\\frac8{c^2}\\mbox{var}^2[\\epsilon] + c \\frac{4T}3 \\int_0^T \\sigma_t^4 dt} \\; Z\n",
    "$$\n",
    "\n",
    "where $Z \\sim N(0,1)$. The optimal constant $c^*$ is given by\n",
    "\n",
    "$$\n",
    "c^* = \\left(\\frac T{12 \\, \\mbox{var}^2[\\epsilon]} \\int_0^T \\sigma_t^4 dt \\right)^{-\\frac13}.\n",
    "$$\n",
    "\n",
    "#### Note\n",
    "In the original paper [Zhang, Mykland and Aït-Sahalia]<sup id=\"cite_ref-ZMA\" class=\"reference\"><a href=\"#cite_note-ZMA\">[9]</a></sup>, the authors suggested the estimator as $[Y]_T^{avg} - \\frac{\\bar n_K}{n}[Y]_T^\\Pi$, whereas the estimator $[Y]_T^{ZMA}$ obtained above is referred to as the *small-sample adjustment* in the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Zhou estimator\n",
    "\n",
    "Define\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "[Y]_T^{\\Pi, Z}: &=& \\sum_{i=1}^n \\, (\\Delta Y_{t_i})^2\n",
    "+ \\sum_{i=2}^n \\, \\Delta Y_{t_i} \\, \\Delta Y_{t_{i-1}} + \\sum_{i=1}^{n-1} \\, \\Delta Y_{t_i} \\Delta Y_{t_{i+1}} \\\\\n",
    "&=& \\sum_{i=1}^n \\,(Y_{t_i} - Y_{t_{i-1}})(Y_{t_{i+1}} - Y_{t_{i-2}}).\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "Thus, under the assumption $Y = X + \\epsilon$ of serially uncorrelated\n",
    "noise independent of returns $X$, we obtain\n",
    "$\\mathbb{E}\\left[[Y]^{\\Pi, Z}\\right] = \\Eof{[X]_T}$. \n",
    "\n",
    "By further assume $X_t = \\sigma W_{\\tau(t)}$ (a time-changed Brownian motion) for some Brownian motion $W$ and deterministic increasing function $\\tau(\\cdot)$, since \n",
    "\n",
    "$$\n",
    "\\Eof{(\\Delta X_{t_i})^2} = \\sigma^2 \\Eof{\\left\\{ W_{\\tau(t_i)} - W_{\\tau(t_{i-1})} \\right\\}^2} = \\sigma^2 \\{\\tau(t_i) - \\tau(t_{i-1})\\},\n",
    "$$\n",
    "\n",
    "we have\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[[Y]^{\\Pi, Z}\\right] = \\sigma^2 \\{\\tau(T) - \\tau(0) \\} = \\angl{X}_T.\n",
    "$$\n",
    "\n",
    "In other words, in this case $[Y]^{\\Pi, Z}$ is an unbiased estimator of $\\angl{X}_T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realized library\n",
    "\n",
    "Realized Library at Oxford-Man Institute of Quantitative Finance publishes daily realized variances/volatilities for various indices. \n",
    "\n",
    "[https://realized.oxford-man.ox.ac.uk/](https://realized.oxford-man.ox.ac.uk/)\n",
    "\n",
    "#### Note\n",
    "<font color=blue>Unfortunately, the Realized Library has ceased providing the service.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPX realized variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('OxfordManRealizedVolatilityIndices.csv', index_col=0, header=2)\n",
    "rv1 = pd.DataFrame(index=df.index)\n",
    "for col in df.columns:\n",
    "    if col[-3:] == '.rk':\n",
    "        rv1[col] = df[col]\n",
    "\n",
    "# convert index into datetime\n",
    "rv1.index = [dt.strptime(str(date), \"%Y%m%d\") for date in rv1.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spx realized variance\n",
    "# spx2.rk contains the rv calcuated by the realized kernel within 5-min bins\n",
    "spx_rv = pd.DataFrame(rv1['SPX2.rk'])\n",
    "spx_rv.plot(color='red', grid=True, title='SPX realized variance',\n",
    "         figsize=(12, 6), ylim=(0,0.003));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Corsi HAR-RV forecast\n",
    "\n",
    "-   The Corsi HAR-RV model implements a regression to fit the parameters.\n",
    "\n",
    "-   This model can be regarded as a poor man’s version of a long memory\n",
    "    model such as ARFIMA.\n",
    "\n",
    "    -   True long-memory models such as ARFIMA are notoriously hard to\n",
    "        fit.\n",
    "\n",
    "-   HAR-RV can also be considered an intelligent alternative to GARCH.\n",
    "\n",
    "-   The model boils down to the regression\n",
    "\n",
    "    $$RV_{t,t+h} = \\beta_0 + \\beta_D\\,RV_t + \\beta_W\\,RV_{t-5,t} + \\beta_M\\,RV_{t-22,t} + \\epsilon_{t,t+h}.$$\n",
    "    \n",
    "    In words, the RV forecast for $h$ days from now is a linear\n",
    "    combination of the current realized variance and (aggregate) RV\n",
    "    estimates for the last week and the last month.\n",
    "    \n",
    "### Note\n",
    "- $RV$ denotes the logarithm of realized variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take h = 1 in the HAR-RV model\n",
    "# y = RV_{t+h}\n",
    "# rv1 = RV_t\n",
    "# rv5 = RV_{t-5}\n",
    "# rv22 = RV_{t-22}\n",
    "spx_rv = spx_rv.dropna()\n",
    "spx1 = np.array(spx_rv)\n",
    "y = spx1[22:]\n",
    "rv1 = spx1[21:-1]\n",
    "rv5 = np.array(pd.DataFrame(spx1[17:]).rolling(5).mean()[5-1:-1])\n",
    "rv22 = np.array(pd.DataFrame(spx1[:]).rolling(22).mean()[22-1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress y over rv1 + rv5 + rv22\n",
    "data = {'y': y, 'rv1': rv1, 'rv5': rv5, 'rv22': rv22}\n",
    "fit_har = sm.ols('y ~ rv1 + rv5 + rv22', data=data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_har.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_har.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert fitted values into pd.DataFrame\n",
    "fitted = pd.DataFrame({'fitted': np.array(fit_har.fittedvalues)}, index=spx_rv[22:].index)\n",
    "fitted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(spx_rv, color='red', ls='dotted', label='Observed RV')\n",
    "plt.plot(fitted, 'b', label='Forecasted RV')\n",
    "plt.title('Observed and forecasted RV based on HAR model', fontsize=20, fontweight='bold')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### References\n",
    "<br />\n",
    "\n",
    "<div class=\"reflist\" style=\"list-style-type: decimal;\">\n",
    "\n",
    "<ol>\n",
    "  \n",
    "  <li id=\"cite_note-Corsi\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Corsi\">^</a></b></span>Fulvio Corsi, A simple approximate long-memory model of realized\n",
    "volatility, <span>*Journal of Financial Econometrics*</span>\n",
    "<span>**7**</span>(2) 174–196 (2009). </li>\n",
    "  \n",
    "  <li id=\"cite_note-ZMA\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ZMA\">^</a></b></span>Lan Zhang, Per A. Mykland and Yacine Aït-Sahalia, A tale of two time scales: Determining intergrated volatility with noise high-frequency data, <span>*Journal of the American Statistical Association*</span>,\n",
    "<span>**100**</span>(472), 1394–1411 (2005).\n",
    "  </li>\n",
    "  \n",
    "  <li id=\"cite_note-Zhou\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Zhou\">^</a></b></span>Bin Zhou, High-frequency data and volatility in foreign-exchange rates, <span>*Journal of Business & Economic Statistics*</span>, \n",
    "<span>**14**</span>(1), 45–52 (1996).\n",
    "  </li>\n",
    "</ol>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
